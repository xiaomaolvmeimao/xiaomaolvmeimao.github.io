---
layout:     post
title:      Language Models are Unsupervised Multitask Learners (GPT-2)
author:     Jexus
tags: 		NLP deep_learning slide
subtitle:   OpenAI 2019 paper - slide
category:  slideshare
---
## Language Models are Unsupervised Multitask Learners (GPT-2)

[Paper Link](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

### TL;DR:

用 Transformer-based (left-to-right) language model 在極大語料 (40GB) 上做訓練，並將所有 NLP 問題轉化成 language model 問題來解，是亂做一通，但也在一些 task (CoQA) 上有著還可以的表現，而另也有生成高品質文章的用途。

<!-- ### Applications -->

- 可於此 blog 觀賞其所產生之優美獨角獸文章：https://openai.com/blog/better-language-models/

- 可於此網站線上享用 GPT-2 的續寫功能：https://talktotransformer.com/

- 可於此網站使用有 GPT-2 幫你續寫的文字編輯器：https://transformer.huggingface.co/

- 可於此網站安裝 GPT-2 所搭建的 code 補全外掛程式：https://tabnine.com/

### Slide:

> Please wait a minute for the embedded frame to be displayed. Reading it on a computer screen is better.



<iframe src="https://onedrive.live.com/embed?cid=255C96F3631B0025&amp;resid=255C96F3631B0025%21419&amp;authkey=APv634WYv6U1ts4&amp;em=2&amp;wdAr=1.7777777777777777" width="962px" height="565px" frameborder="0">這是 <a target="_blank" href="https://office.com/webapps">Office</a> 提供的內嵌 <a target="_blank" href="https://office.com">Microsoft Office</a> 簡報。</iframe>